{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Section_3_BERT.ipynb","provenance":[{"file_id":"11k7s9Owpjzzpee0FdELzrmfZL1Dv1LaV","timestamp":1626279023165},{"file_id":"1gNCSDCsjlE94Y-zH2Z6-LwACvtyqT28o","timestamp":1590777517115}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"8efa10950bd34b4580847dc19be5ea99":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e5188794050645eb82d03f0daaeb5947","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_462408668b4147e2b6cbdab5b3eb3fb0","IPY_MODEL_d0b490fe2e3d46a18b45cc6c84ca4742"]}},"e5188794050645eb82d03f0daaeb5947":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"462408668b4147e2b6cbdab5b3eb3fb0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1975e2578c404899b8cf2e4c988c7457","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":213450,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":213450,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1c780a707cae4a8f9737d8bdb07162e1"}},"d0b490fe2e3d46a18b45cc6c84ca4742":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e67d244750d7413baf976b1c8275a5a4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 213k/213k [00:02&lt;00:00, 104kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_df2be4d5d5eb4b1fac1654ce56ab9b23"}},"1975e2578c404899b8cf2e4c988c7457":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1c780a707cae4a8f9737d8bdb07162e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e67d244750d7413baf976b1c8275a5a4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"df2be4d5d5eb4b1fac1654ce56ab9b23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5346df87b2224db69145da0ee37d4353":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_668a9cbb8e7b4abab93985ddf5d2d6f0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2b7750a5fe9b4b0983bc0b3df1763a14","IPY_MODEL_56f4f549a82b4136a5ea86c6e445349e"]}},"668a9cbb8e7b4abab93985ddf5d2d6f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2b7750a5fe9b4b0983bc0b3df1763a14":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c73883c3d363415a9c0518a5ea1b6090","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":29,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":29,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1e1222ffec194280aec446c6471ff6a9"}},"56f4f549a82b4136a5ea86c6e445349e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_740a62659d014f009f3149657f3d7a2c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 29.0/29.0 [00:00&lt;00:00, 37.1B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_acfbd166cf4843809219ee2f3b2c2ef7"}},"c73883c3d363415a9c0518a5ea1b6090":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1e1222ffec194280aec446c6471ff6a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"740a62659d014f009f3149657f3d7a2c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"acfbd166cf4843809219ee2f3b2c2ef7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"80c06c4b51e74de0a82d691e5cc12118":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4a11e03f8a454b02a537fb8c02846354","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3d3eb656ec8e4135a6f6819b27624f36","IPY_MODEL_eff02935a82d49858651c5dd7086277b"]}},"4a11e03f8a454b02a537fb8c02846354":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3d3eb656ec8e4135a6f6819b27624f36":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e11e8cd46c1f4e7aa89006b246c37395","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":435797,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":435797,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a9b3428345b343b5825c22b638aa98af"}},"eff02935a82d49858651c5dd7086277b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_11c9a1c90ccb4f619c96cc29050822de","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 436k/436k [00:00&lt;00:00, 2.60MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b0e8cd56cf9142aeacb667b6d9745b83"}},"e11e8cd46c1f4e7aa89006b246c37395":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a9b3428345b343b5825c22b638aa98af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"11c9a1c90ccb4f619c96cc29050822de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b0e8cd56cf9142aeacb667b6d9745b83":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d71a65445c5d4e63a06b6cd8251166f2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_66c4c9e1364b4ff79aac17f5afbbb6e2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_19b6ef6a14ad46a1a5b2ac0eadc28ae4","IPY_MODEL_93088c64ece0470aabcd39247980d298"]}},"66c4c9e1364b4ff79aac17f5afbbb6e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"19b6ef6a14ad46a1a5b2ac0eadc28ae4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d359496ef7fc4301ae0f8a07e34d580a","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":570,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":570,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_28d2da75bd4b48759ca81625b88ea68b"}},"93088c64ece0470aabcd39247980d298":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_37eb853cd78c4a1ab87b8648990bec13","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 570/570 [00:00&lt;00:00, 988B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_959af3caca6b4e388a30c1bf4c7b93e1"}},"d359496ef7fc4301ae0f8a07e34d580a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"28d2da75bd4b48759ca81625b88ea68b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"37eb853cd78c4a1ab87b8648990bec13":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"959af3caca6b4e388a30c1bf4c7b93e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"627576dc8c024ee7b57597e3b0b62e73":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_517d3bdfee4c474d85482626ba42e670","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1315cd43b7074390908954c8a851b388","IPY_MODEL_3eea97312c164b7b8485b8706f8ec1f6"]}},"517d3bdfee4c474d85482626ba42e670":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1315cd43b7074390908954c8a851b388":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b359d476c63c4f9f9a44ecf54f32e75a","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":526681800,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":526681800,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_28fa5b8accdd42379ed8f1f87938e765"}},"3eea97312c164b7b8485b8706f8ec1f6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_99ac134a64dc4c979d16e3623377b0ff","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 527M/527M [00:16&lt;00:00, 31.3MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c3cf084b9dfe47688643390e1be997f8"}},"b359d476c63c4f9f9a44ecf54f32e75a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"28fa5b8accdd42379ed8f1f87938e765":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"99ac134a64dc4c979d16e3623377b0ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c3cf084b9dfe47688643390e1be997f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"CR8QBiJErfGb"},"source":["# Classifying Voice Commands\n","\n","For voice commands, Siri needs to be able to figure out *what* the speaker wants, and then *how* to accomplish that request. \n","\n","<img src=\"https://www.cheatsheet.com/wp-content/uploads/2016/01/Siri-in-iOS-9-640x305.png\" width=400>\n","\n","Recall that we had a two-part goal:\n","\n","a) predict the intent of the speaker of a voice command \n","\n","and \n","\n","b) extract the interesting named entities within the command.\n","\n","It's now time to focus on part (b), also known as **NER**, which will help our sentence-level classification system we started in the 2nd notebook!\n","\n","<img src=\"https://miro.medium.com/max/2594/1*rq7FCkcq4sqUY9IgfsPEOg.png\" width=\"500\">\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"dlE9nndIa-4-"},"source":["In this notebook we'll be:\n","*   Implementing ML models for Intent Classification\n","\n"]},{"cell_type":"markdown","metadata":{"id":"omFcoJMi5ESw"},"source":["**IMPORTANT**: Since the BERT model we will be using in this notebook is so large, we need to do one step before continuing. Please go to the 'Runtime' tab, and click on 'Change Runtime Type'; then select **GPU** under the dropdown for Hardware accelerator."]},{"cell_type":"code","metadata":{"id":"IGoMnG4dsXXi","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["8efa10950bd34b4580847dc19be5ea99","e5188794050645eb82d03f0daaeb5947","462408668b4147e2b6cbdab5b3eb3fb0","d0b490fe2e3d46a18b45cc6c84ca4742","1975e2578c404899b8cf2e4c988c7457","1c780a707cae4a8f9737d8bdb07162e1","e67d244750d7413baf976b1c8275a5a4","df2be4d5d5eb4b1fac1654ce56ab9b23","5346df87b2224db69145da0ee37d4353","668a9cbb8e7b4abab93985ddf5d2d6f0","2b7750a5fe9b4b0983bc0b3df1763a14","56f4f549a82b4136a5ea86c6e445349e","c73883c3d363415a9c0518a5ea1b6090","1e1222ffec194280aec446c6471ff6a9","740a62659d014f009f3149657f3d7a2c","acfbd166cf4843809219ee2f3b2c2ef7","80c06c4b51e74de0a82d691e5cc12118","4a11e03f8a454b02a537fb8c02846354","3d3eb656ec8e4135a6f6819b27624f36","eff02935a82d49858651c5dd7086277b","e11e8cd46c1f4e7aa89006b246c37395","a9b3428345b343b5825c22b638aa98af","11c9a1c90ccb4f619c96cc29050822de","b0e8cd56cf9142aeacb667b6d9745b83","d71a65445c5d4e63a06b6cd8251166f2","66c4c9e1364b4ff79aac17f5afbbb6e2","19b6ef6a14ad46a1a5b2ac0eadc28ae4","93088c64ece0470aabcd39247980d298","d359496ef7fc4301ae0f8a07e34d580a","28d2da75bd4b48759ca81625b88ea68b","37eb853cd78c4a1ab87b8648990bec13","959af3caca6b4e388a30c1bf4c7b93e1","627576dc8c024ee7b57597e3b0b62e73","517d3bdfee4c474d85482626ba42e670","1315cd43b7074390908954c8a851b388","3eea97312c164b7b8485b8706f8ec1f6","b359d476c63c4f9f9a44ecf54f32e75a","28fa5b8accdd42379ed8f1f87938e765","99ac134a64dc4c979d16e3623377b0ff","c3cf084b9dfe47688643390e1be997f8"]},"executionInfo":{"status":"ok","timestamp":1626279278575,"user_tz":420,"elapsed":41823,"user":{"displayName":"Kripa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg6SX3WlQTXibD6hgiep50H9CpJepKU0fmumT7JAs0=s64","userId":"16311629485750149971"}},"outputId":"29e7e026-a358-482e-9734-0cf17b129451"},"source":["#@title Run this code to get started\n","%tensorflow_version 2.x\n","%pip install -q transformers\n","\n","import tensorflow as tf\n","from urllib.request import urlretrieve\n","from pathlib import Path\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","from transformers import BertTokenizer\n","from transformers import TFBertModel\n","from tensorflow.keras.layers import Dropout, Dense\n","from tensorflow.keras.losses import SparseCategoricalCrossentropy\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.metrics import SparseCategoricalAccuracy\n","\n","model_name = \"bert-base-cased\"\n","tokenizer = BertTokenizer.from_pretrained(model_name)\n","\n","# SNIPS_DATA_BASE_URL = (\n","#     \"https://github.com/ogrisel/slot_filling_and_intent_detection_of_SLU/blob/\"\n","#     \"master/data/snips/\"\n","# )\n","# for filename in [\"train\", \"valid\", \"test\", \"vocab.intent\", \"vocab.slot\"]:\n","#     path = Path(filename)\n","#     if not path.exists():\n","#       print(f\"Downloading {filename}...\")\n","#       urlretrieve(SNIPS_DATA_BASE_URL + filename + \"?raw=true\", path)\n","\n","!wget 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Siri%20(Bert)%20Voice%20Commands/train'\n","!wget 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Siri%20(Bert)%20Voice%20Commands/valid'\n","!wget 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Siri%20(Bert)%20Voice%20Commands/test'\n","!wget 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Siri%20(Bert)%20Voice%20Commands/vocab.intent'\n","!wget 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Siri%20(Bert)%20Voice%20Commands/vocab.slot'\n","\n","\n","\n","def parse_line(line):\n","    data, intent_label = line.split(\" <=> \")\n","    items = data.split()\n","    words = [item.rsplit(\":\", 1)[0]for item in items]\n","    word_labels = [item.rsplit(\":\", 1)[1]for item in items]\n","    return {\n","        \"intent_label\": intent_label, \n","        \"words\": \" \".join(words),\n","        \"word_labels\": \" \".join(word_labels),\n","        \"length\": len(words),\n","    }\n","\n","def encode_dataset(text_sequences):\n","    # Create token_ids array (initialized to all zeros), where \n","    # rows are a sequence and columns are encoding ids\n","    # of each token in given sequence.\n","    token_ids = np.zeros(shape=(len(text_sequences), max_token_len),\n","                         dtype=np.int32)\n","    \n","    for i, text_sequence in enumerate(text_sequences):\n","        encoded = tokenizer.encode(text_sequence)\n","        token_ids[i, 0:len(encoded)] = encoded\n","\n","    attention_masks = (token_ids != 0).astype(np.int32)\n","    return {\"input_ids\": token_ids, \"attention_masks\": attention_masks}\n","\n","\n","train_lines = Path(\"train\").read_text().strip().splitlines()\n","valid_lines = Path(\"valid\").read_text().strip().splitlines()\n","test_lines = Path(\"test\").read_text().strip().splitlines()\n","\n","df_train = pd.DataFrame([parse_line(line) for line in train_lines])\n","df_valid = pd.DataFrame([parse_line(line) for line in valid_lines])\n","df_test = pd.DataFrame([parse_line(line) for line in test_lines])\n","\n","max_token_len = 43\n","\n","encoded_train = encode_dataset(df_train[\"words\"])\n","encoded_valid = encode_dataset(df_valid[\"words\"])\n","encoded_test = encode_dataset(df_test[\"words\"])\n","\n","intent_names = Path(\"vocab.intent\").read_text().split()\n","intent_map = dict((label, idx) for idx, label in enumerate(intent_names))\n","intent_train = df_train[\"intent_label\"].map(intent_map).values\n","intent_valid = df_valid[\"intent_label\"].map(intent_map).values\n","intent_test = df_test[\"intent_label\"].map(intent_map).values\n","\n","base_bert_model = TFBertModel.from_pretrained(\"bert-base-cased\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 2.5MB 7.7MB/s \n","\u001b[K     |████████████████████████████████| 3.3MB 48.5MB/s \n","\u001b[K     |████████████████████████████████| 901kB 23.0MB/s \n","\u001b[?25h"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8efa10950bd34b4580847dc19be5ea99","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5346df87b2224db69145da0ee37d4353","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=29.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"80c06c4b51e74de0a82d691e5cc12118","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435797.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","--2021-07-14 16:14:12--  https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Siri%20(Bert)%20Voice%20Commands/train\n","Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.202.128, 74.125.142.128, 74.125.195.128, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.202.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1793794 (1.7M) [application/octet-stream]\n","Saving to: ‘train’\n","\n","\rtrain                 0%[                    ]       0  --.-KB/s               \rtrain               100%[===================>]   1.71M  --.-KB/s    in 0.009s  \n","\n","2021-07-14 16:14:12 (193 MB/s) - ‘train’ saved [1793794/1793794]\n","\n","--2021-07-14 16:14:12--  https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Siri%20(Bert)%20Voice%20Commands/valid\n","Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.195.128, 108.177.98.128, 74.125.199.128, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.195.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 98609 (96K) [application/octet-stream]\n","Saving to: ‘valid’\n","\n","valid               100%[===================>]  96.30K  --.-KB/s    in 0.001s  \n","\n","2021-07-14 16:14:12 (104 MB/s) - ‘valid’ saved [98609/98609]\n","\n","--2021-07-14 16:14:12--  https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Siri%20(Bert)%20Voice%20Commands/test\n","Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.99.128, 74.125.199.128, 173.194.202.128, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.99.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 96761 (94K) [application/octet-stream]\n","Saving to: ‘test’\n","\n","test                100%[===================>]  94.49K  --.-KB/s    in 0.001s  \n","\n","2021-07-14 16:14:12 (137 MB/s) - ‘test’ saved [96761/96761]\n","\n","--2021-07-14 16:14:12--  https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Siri%20(Bert)%20Voice%20Commands/vocab.intent\n","Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.99.128, 74.125.199.128, 173.194.202.128, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.99.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 99 [application/octet-stream]\n","Saving to: ‘vocab.intent’\n","\n","vocab.intent        100%[===================>]      99  --.-KB/s    in 0s      \n","\n","2021-07-14 16:14:12 (21.2 MB/s) - ‘vocab.intent’ saved [99/99]\n","\n","--2021-07-14 16:14:12--  https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Siri%20(Bert)%20Voice%20Commands/vocab.slot\n","Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.197.128, 74.125.199.128, 74.125.142.128, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.197.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 994 [application/octet-stream]\n","Saving to: ‘vocab.slot’\n","\n","vocab.slot          100%[===================>]     994  --.-KB/s    in 0s      \n","\n","2021-07-14 16:14:12 (21.8 MB/s) - ‘vocab.slot’ saved [994/994]\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d71a65445c5d4e63a06b6cd8251166f2","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"627576dc8c024ee7b57597e3b0b62e73","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=526681800.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"hg6IkYg-sXBM"},"source":["## Intent Classification + NER\n","\n","Let's now refine our Natural Language Understanding system by capturing the important named elements within each voice command.\n","\n","To do this, we will do word (actually *token*) level classification of the BIO labels.\n","\n","```\n","      Book : O\n","         a : O\n","     table : O\n","       for : O\n","       two : B-party_size_number\n","        at : O\n","        Le : B-restaurant_name\n","         R : I-restaurant_name\n","     ##itz : I-restaurant_name\n","       for : O\n","    Friday : B-timeRange\n","     night : I-timeRange\n","         ! : O\n","```\n","\n","Note: Since we have *word* level tags but BERT uses a tokenizer, we need to align the BIO labels with the BERT *tokens*."]},{"cell_type":"markdown","metadata":{"id":"-Bv9qrtdsogG"},"source":["First, let's load the list of possible word token labels and augment it with an additional padding label so we can ignore special tokens:"]},{"cell_type":"code","metadata":{"id":"_HtO77h2snDB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626279533452,"user_tz":420,"elapsed":162,"user":{"displayName":"Kripa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg6SX3WlQTXibD6hgiep50H9CpJepKU0fmumT7JAs0=s64","userId":"16311629485750149971"}},"outputId":"6f9dba64-c108-48c3-a9de-f9e23c95cf50"},"source":["# Build a map from slot name to a unique id.\n","slot_names = [\"[PAD]\"] + Path(\"vocab.slot\").read_text().strip().splitlines()\n","slot_map = {}\n","for label in slot_names:\n","    slot_map[label] = len(slot_map)\n","slot_map"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'B-album': 1,\n"," 'B-artist': 2,\n"," 'B-best_rating': 3,\n"," 'B-city': 4,\n"," 'B-condition_description': 5,\n"," 'B-condition_temperature': 6,\n"," 'B-country': 7,\n"," 'B-cuisine': 8,\n"," 'B-current_location': 9,\n"," 'B-entity_name': 10,\n"," 'B-facility': 11,\n"," 'B-genre': 12,\n"," 'B-geographic_poi': 13,\n"," 'B-location_name': 14,\n"," 'B-movie_name': 15,\n"," 'B-movie_type': 16,\n"," 'B-music_item': 17,\n"," 'B-object_location_type': 18,\n"," 'B-object_name': 19,\n"," 'B-object_part_of_series_type': 20,\n"," 'B-object_select': 21,\n"," 'B-object_type': 22,\n"," 'B-party_size_description': 23,\n"," 'B-party_size_number': 24,\n"," 'B-playlist': 25,\n"," 'B-playlist_owner': 26,\n"," 'B-poi': 27,\n"," 'B-rating_unit': 28,\n"," 'B-rating_value': 29,\n"," 'B-restaurant_name': 30,\n"," 'B-restaurant_type': 31,\n"," 'B-served_dish': 32,\n"," 'B-service': 33,\n"," 'B-sort': 34,\n"," 'B-spatial_relation': 35,\n"," 'B-state': 36,\n"," 'B-timeRange': 37,\n"," 'B-track': 38,\n"," 'B-year': 39,\n"," 'I-album': 40,\n"," 'I-artist': 41,\n"," 'I-city': 42,\n"," 'I-country': 43,\n"," 'I-cuisine': 44,\n"," 'I-current_location': 45,\n"," 'I-entity_name': 46,\n"," 'I-facility': 47,\n"," 'I-genre': 48,\n"," 'I-geographic_poi': 49,\n"," 'I-location_name': 50,\n"," 'I-movie_name': 51,\n"," 'I-movie_type': 52,\n"," 'I-music_item': 53,\n"," 'I-object_location_type': 54,\n"," 'I-object_name': 55,\n"," 'I-object_part_of_series_type': 56,\n"," 'I-object_select': 57,\n"," 'I-object_type': 58,\n"," 'I-party_size_description': 59,\n"," 'I-playlist': 60,\n"," 'I-playlist_owner': 61,\n"," 'I-poi': 62,\n"," 'I-restaurant_name': 63,\n"," 'I-restaurant_type': 64,\n"," 'I-served_dish': 65,\n"," 'I-service': 66,\n"," 'I-sort': 67,\n"," 'I-spatial_relation': 68,\n"," 'I-state': 69,\n"," 'I-timeRange': 70,\n"," 'I-track': 71,\n"," 'O': 72,\n"," '[PAD]': 0}"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"XH8T5IuKsw5-"},"source":["#### Word to Token Encodings\n","\n","The following function generates *token-aligned* integer ids from the BIO *word-level* annotations. <img src=\"https://www.emoji.co.uk/files/twitter-emojis/symbols-twitter/11214-anticlockwise-downwards-and-upwards-open-circle-arrows.png\" width=20>\n","\n","If a certain word is broken down into multiple tokens by BERT, the word-level label is replicated for all of the word's tokens. The \"B-\" prefix is only used for the 1st of the tokens, while the rest of the tokens have the same label but with the \"I-\" prefix.\n","\n"]},{"cell_type":"code","metadata":{"id":"WeChi7UlsxWQ"},"source":["# Uses the slot_map of slot name to unique id, defined above, as well\n","# as the BERT tokenizer, to create a np array with each row corresponding\n","# to a given sequence, and the columns as the id of the given token slot labels.\n","def encode_token_labels(text_sequences, true_word_labels):\n","    encoded = np.zeros(shape=(len(text_sequences), max_token_len), dtype=np.int32)\n","    for i, (text_sequence, word_labels) in enumerate( \\\n","            zip(text_sequences, true_word_labels)):\n","        encoded_labels = []\n","        for word, word_label in zip(text_sequence.split(), word_labels.split()):\n","            tokens = tokenizer.tokenize(word)\n","            encoded_labels.append(slot_map[word_label])\n","            expand_label = word_label.replace(\"B-\", \"I-\")\n","            if not expand_label in slot_map:\n","                expand_label = word_label\n","            encoded_labels.extend([slot_map[expand_label]] * (len(tokens) - 1))\n","        encoded[i, 1:len(encoded_labels) + 1] = encoded_labels\n","    return encoded"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yqgjn30y45RV"},"source":["#### Exercise 1\n","\n","Let's encode the token labels for train, validation, & test:"]},{"cell_type":"code","metadata":{"id":"2_E2mYLys06d"},"source":["# Encode the token labels and store in variables slot_train, slot_valid, slot_test.\n","### YOUR CODE HERE ###\n","df_train.head()\n","slot_train = encode_token_labels(df_train[\"words\"], df_train[\"word_labels\"])\n","\n","df_valid.head()\n","slot_valid = encode_token_labels(df_valid[\"words\"], df_valid[\"word_labels\"])\n","\n","df_test.head()\n","slot_test = encode_token_labels(df_test[\"words\"], df_test[\"word_labels\"])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lZG9hgDUtYYZ"},"source":["Let's look at what the encoded token labels for the 1st training sequence are:"]},{"cell_type":"code","metadata":{"id":"rXc6Tzlks3Tn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626280384742,"user_tz":420,"elapsed":243,"user":{"displayName":"Kripa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg6SX3WlQTXibD6hgiep50H9CpJepKU0fmumT7JAs0=s64","userId":"16311629485750149971"}},"outputId":"507d0116-6d3e-47ad-9460-08f67432419d"},"source":["slot_train[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 0, 72, 72, 10, 46, 46, 46, 72, 26, 25, 60, 60, 60, 60, 60, 60, 72,\n","       72,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  0,  0,  0,  0,  0], dtype=int32)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"Fb-CwwQntcHG"},"source":["Remember that special tokens such as `[PAD]` and `[SEP]` as well as all padded positions have a 0 label."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"jp8KihdB31O5","executionInfo":{"status":"ok","timestamp":1626280526257,"user_tz":420,"elapsed":220,"user":{"displayName":"Kripa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg6SX3WlQTXibD6hgiep50H9CpJepKU0fmumT7JAs0=s64","userId":"16311629485750149971"}},"outputId":"f2e45de7-44b7-4ddd-cb62-0b97fb6e7b4d"},"source":["df_train.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>intent_label</th>\n","      <th>words</th>\n","      <th>word_labels</th>\n","      <th>length</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>AddToPlaylist</td>\n","      <td>Add Don and Sherri to my Meditate to Sounds of...</td>\n","      <td>O B-entity_name I-entity_name I-entity_name O ...</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>AddToPlaylist</td>\n","      <td>put United Abominations onto my rare groove pl...</td>\n","      <td>O B-entity_name I-entity_name O B-playlist_own...</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>AddToPlaylist</td>\n","      <td>add the tune by misato watanabe to the Trapeo ...</td>\n","      <td>O O B-music_item O B-artist I-artist O O B-pla...</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>AddToPlaylist</td>\n","      <td>add this artist to my this is miguel bosé play...</td>\n","      <td>O O B-music_item O B-playlist_owner B-playlist...</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>AddToPlaylist</td>\n","      <td>add heresy and the hotel choir to the evening ...</td>\n","      <td>O B-entity_name I-entity_name I-entity_name I-...</td>\n","      <td>11</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    intent_label  ... length\n","0  AddToPlaylist  ...     12\n","1  AddToPlaylist  ...      8\n","2  AddToPlaylist  ...     10\n","3  AddToPlaylist  ...     10\n","4  AddToPlaylist  ...     11\n","\n","[5 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"-f4ZxkdoteCD"},"source":["#### Exercise 2\n","\n","Let's finish filling out the code below to build our **joint sequence and token classification model** which will be trained on our encoded dataset with the NER labels <img src=\"https://www.dictionary.com/e/wp-content/uploads/2018/08/victory-hand.png\" width=20>:\n"]},{"cell_type":"code","metadata":{"id":"Wn5MWCeOtefa"},"source":["class JointIntentAndSlotFillingModel(tf.keras.Model):\n","\n","    def __init__(self, intent_num_labels=None, slot_num_labels=None,\n","                dropout_prob=0.1):\n","        super().__init__(name=\"joint_intent_slot\")\n","\n","        self.bert = base_bert_model\n","        \n","        self.dropout = Dropout(dropout_prob)\n","        self.intent_classifier = Dense(intent_num_labels)\n","        self.slot_classifier = Dense(slot_num_labels)\n","\n","    def call(self, inputs, **kwargs):\n","        tokens_output, pooled_output = self.bert(inputs, **kwargs, return_dict=False)\n","\n","        tokens_output = self.dropout(tokens_output, \\\n","                                     training=kwargs.get(\"training\", False))\n","        slot_logits = self.slot_classifier(tokens_output)\n","\n","        pooled_output = self.dropout(pooled_output, \\\n","                                     training=kwargs.get(\"training\", False))\n","        intent_logits = self.intent_classifier(pooled_output)\n","\n","        return slot_logits, intent_logits\n","\n","joint_model = JointIntentAndSlotFillingModel(intent_num_labels=len(intent_map),slot_num_labels=len(slot_map))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1t7cP_dWuChJ"},"source":["# Define one classification loss for each output (intent & NER):\n","losses = [SparseCategoricalCrossentropy(from_logits=True),\n","          SparseCategoricalCrossentropy(from_logits=True)]\n","          \n","joint_model.compile(optimizer=Adam(learning_rate=3e-5, epsilon=1e-08),\n","                    loss=losses,\n","                    metrics=[SparseCategoricalAccuracy('accuracy')], run_eagerly=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eWhvmB8puECV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626282702733,"user_tz":420,"elapsed":169033,"user":{"displayName":"Kripa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg6SX3WlQTXibD6hgiep50H9CpJepKU0fmumT7JAs0=s64","userId":"16311629485750149971"}},"outputId":"145e807d-444e-4895-d1fe-a00474643d8e"},"source":["# Train the model.\n","history = joint_model.fit(encoded_train, (slot_train, intent_train), \\\n","    validation_data=(encoded_valid, (slot_valid, intent_valid)), \\\n","    epochs=1, batch_size=32)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["409/409 [==============================] - 169s 412ms/step - loss: nan - output_1_loss: nan - output_2_loss: nan - output_1_accuracy: 0.7399 - output_2_accuracy: 0.1408 - val_loss: nan - val_output_1_loss: nan - val_output_2_loss: nan - val_output_1_accuracy: 0.7316 - val_output_2_accuracy: 0.1429\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MfiWEKr3uF6g"},"source":["We should be able to achieve 99% validation accuracy for both tasks (sequence & token predictions) after only training for one epoch!"]},{"cell_type":"markdown","metadata":{"id":"_FnovtrRuIVl"},"source":["#### Classification\n","\n","<img src=\"https://orbitcarrot.com/wp-content/uploads/2014/12/predict.png\" width=100>\n","\n","Whew! All that's left to make predictions is the following function which uses our trained model to make a prediction on a single text sequence, & display both the sequence-wise and the token-wise class labels.\n"]},{"cell_type":"markdown","metadata":{"id":"nxERz1fj8CjA"},"source":["#### Exercise 3\n","\n","Let's finish the following function to make predictions:"]},{"cell_type":"code","metadata":{"id":"yq9qh16auKqp","colab":{"base_uri":"https://localhost:8080/","height":130},"executionInfo":{"status":"error","timestamp":1626283208110,"user_tz":420,"elapsed":475,"user":{"displayName":"Kripa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg6SX3WlQTXibD6hgiep50H9CpJepKU0fmumT7JAs0=s64","userId":"16311629485750149971"}},"outputId":"ea4039fd-8637-43ac-d75d-87f0f5a24d87"},"source":["# Use the model we trained to get the intent & slot logits\n","# and print the actual string of the class corresponding to\n","# highest logit score for each token, and the sentence overall.\n","def show_predictions(text, intent_names, slot_names):\n","    inputs = tf.constant(tokenizer.encode(text))[None, :]  # batch_size = 1\n","    outputs = None ### YOUR CODE HERE ###\n","    None = outputs  ### YOUR CODE HERE ###\n","    slot_ids = slot_logits.numpy().argmax(axis=-1)[0, 1:-1]\n","    intent_id = intent_logits.numpy().argmax(axis=-1)[0]\n","    print(\"## Intent:\", None)  ### YOUR CODE HERE ###\n","    print(\"## Slots:\")\n","    for token, slot_id in zip(tokenizer.tokenize(text), slot_ids):\n","        print(f\"{token:>10} : {slot_names[slot_id]}\")"],"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-7481ebb17430>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    None = outputs  ### YOUR CODE HERE ###\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to keyword\n"]}]},{"cell_type":"markdown","metadata":{"id":"QvwcHegauMLn"},"source":["Let's see how our classification function works on some examples!"]},{"cell_type":"code","metadata":{"id":"LYp8Z4-AuOGq"},"source":["show_predictions(\"Book a table for two at Le Ritz for Friday night!\", intent_names, slot_names)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4CqNuF_YuPfK"},"source":["show_predictions(\"Will it snow tomorrow in Saclay?\", intent_names, slot_names)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sDijGXG0uQvf"},"source":["show_predictions(\"I would like to listen to Anima by Thom Yorke.\", intent_names, slot_names)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mfwa6MGwuSO8"},"source":["### Turning Predictions into Structured Knowledge\n","\n","A system like Siri shouldn't have to handle any excess information, and ultimately wants to transform a speaker's verbal command into a nice, structured format.\n","\n","For completeness, the following functions turn the predicted BIO token ids and intent id into a simple structured representation: "]},{"cell_type":"code","metadata":{"id":"udnUVXCvuT4e"},"source":["def decode_predictions(text, intent_names, slot_names,\n","                       intent_id, slot_ids):\n","    info = {\"intent\": intent_names[intent_id]}\n","    collected_slots = {}\n","    active_slot_words = []\n","    active_slot_name = None\n","    for word in text.split():\n","        tokens = tokenizer.tokenize(word)\n","        current_word_slot_ids = slot_ids[:len(tokens)]\n","        slot_ids = slot_ids[len(tokens):]\n","        current_word_slot_name = slot_names[current_word_slot_ids[0]]\n","        if current_word_slot_name == \"O\":\n","            if active_slot_name:\n","                collected_slots[active_slot_name] = \" \".join(active_slot_words)\n","                active_slot_words = []\n","                active_slot_name = None\n","        else:\n","            # Naive BIO: handling: treat B- and I- the same...\n","            new_slot_name = current_word_slot_name[2:]\n","            if active_slot_name is None:\n","                active_slot_words.append(word)\n","                active_slot_name = new_slot_name\n","            elif new_slot_name == active_slot_name:\n","                active_slot_words.append(word)\n","            else:\n","                collected_slots[active_slot_name] = \" \".join(active_slot_words)\n","                active_slot_words = [word]\n","                active_slot_name = new_slot_name\n","    if active_slot_name:\n","        collected_slots[active_slot_name] = \" \".join(active_slot_words)\n","    info[\"slots\"] = collected_slots\n","    return info"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C5-mstZjuV52"},"source":["def nlu(text, intent_names, slot_names):\n","    inputs = tf.constant(tokenizer.encode(text))[None, :]  # batch_size = 1\n","    outputs = joint_model(inputs)\n","    slot_logits, intent_logits = outputs\n","    slot_ids = slot_logits.numpy().argmax(axis=-1)[0, 1:-1]\n","    intent_id = intent_logits.numpy().argmax(axis=-1)[0]\n","\n","    return decode_predictions(text, intent_names, slot_names, intent_id, slot_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tWKJnB6euX0f"},"source":["Let's test this on the same examples:"]},{"cell_type":"code","metadata":{"id":"OUNcIW8buZmW"},"source":["nlu(\"Book a table for two at Le Ritz for Friday night\", intent_names, slot_names)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1WruhL1tubsP"},"source":["nlu(\"Will it snow tomorrow in Saclay\", intent_names, slot_names)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OiVegtxAudAj"},"source":["nlu(\"I would like to listen to Anima by Thom Yorke\", intent_names, slot_names)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zM6dR0bl0C7V"},"source":["**Discuss**:\n","\n","We focused on the NLU/NLP aspect of turning a string of words in a verbal command into a simple representation for Siri to utilize.\n","\n","What do you think Siri would actually do next with those structured predictions?"]},{"cell_type":"markdown","metadata":{"id":"kZxnxXzzuedG"},"source":["## Limitations\n","\n","1. **Language**\n","\n","BERT is pretrained primarily on English content. Therefore, it will extract features on English text.\n","\n","Note that there are alternative pretrained models that use a mix of different languages (e.g. [XLM](https://github.com/facebookresearch/XLM/)) and certain models that have been trained on other languages entirely. For instance [CamemBERT](https://camembert-model.fr/) is pretrained on French text. Both kinds of models are available in the transformers package:\n","\n","https://github.com/huggingface/transformers#model-architectures\n","\n","The public SNIPS dataset we used is for fine-tuning in English only. To build a model for another language we would need to collect and annotate a similar corpus (body of text) with diverse, representative samples.\n","\n","\n","2. **Biases in the Pre-Trained Model**\n","\n","The original data used to pre-train BERT was collected from the Internet and contains a multitude of data, including offensive and hateful speech.\n","\n","While using BERT for our voice command understanding system is unlikely to be impacted by those biases, it could be a serious problem for other kinds of applications.\n","\n","It is therefore strongly recommended to spend time auditing any biases that are embedded in pre-trained models before ever actually deploying system that derives from them.\n","\n","3. **Computational Resources**\n","\n","The original BERT model has many parameters which takes up a lot of memory. It is also very computationally intensive and usually requires powerful [GPUs](https://en.wikipedia.org/wiki/Graphics_processing_unit) or [TPUs](https://en.wikipedia.org/wiki/Tensor_processing_unit) to process data at a *reasonable* speed (both for training and testing).\n","\n","Designing alternative architectures with fewer parameters or more efficient training and prediction methods is still an area of active research.\n","\n","Depending on the problem, simpler architectures based on convolutional neural networks (CNNs) and LSTMs might have a better speed / accuracy trade-off."]}]}